{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: skyblue; font-family: 'Times New Roman', serif; color: white; padding: 20px; font-size: 36px; font-weight: bold; border-radius: 15px; box-shadow: 0px 6px 15px rgba(0, 0, 0, 0.2); transition: all 0.3s ease;\">\n",
    "    INTRODUCTION TO DATA SCIENCE<br>\n",
    "    @ FIT-HCMUS, VNU-HCM<br>\n",
    "    FINAL PROJECT üè´\n",
    "</div>\n",
    "<style>\n",
    "    div:hover {\n",
    "        transform: scale(1.05);\n",
    "        box-shadow: 0px 10px 20px rgba(0, 0, 0, 0.3);\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #ADD8E6; font-family: 'Times New Roman', serif; color: white; padding: 20px; font-size: 30px; font-weight: bold; border-radius: 10px; box-shadow: 0px 6px 15px rgba(0, 0, 0, 0.2); transition: all 0.3s ease;\">\n",
    "    THE ANALYSIS OF THE MOBILE PHONE MARKET AT MOBILE CITY STORE\n",
    "</div>\n",
    "<style>\n",
    "    div:hover {\n",
    "        transform: scale(1.05);\n",
    "        box-shadow: 0px 10px 20px rgba(0, 0, 0, 0.3);\n",
    "    }\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #ADD8E6; font-family: 'Times New Roman', serif; color: white; padding: 25px; font-size: 20px; font-weight: bold; border-radius: 10px; box-shadow: 0px 6px 15px rgba(0, 0, 0, 0.2); transition: all 0.3s ease;\">\n",
    "    DATA COLLECTION\n",
    "</div>\n",
    "<style>\n",
    "    div:hover {\n",
    "        opacity: 0.8;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ng∆∞·ªùi th·ª±c hi·ªán**: B√πi ƒê√¨nh B·∫£o\n",
    "\n",
    "**MSSV**: 21120201\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S·ª≠ d·ª•ng Selenium k·∫øt h·ª£p v·ªõi BeautySoup ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import csv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L·∫•y th·ªùi gian hi·ªán t·∫°i v√† c√†i ƒë·∫∑t tr√¨nh duy·ªát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th·ªùi gian b·∫Øt ƒë·∫ßu thu th·∫≠p: 2024-12-18 07:28:23\n"
     ]
    }
   ],
   "source": [
    "# Get current time\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "# Print the current time\n",
    "print(\"Th·ªùi gian b·∫Øt ƒë·∫ßu thu th·∫≠p:\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o instance c·ªßa tr√¨nh duy·ªát\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Ph√≥ng to tr√¨nh duy·ªát\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫øn t·ª´ng trang ƒëi·ªán tho·∫°i chi ti·∫øt t·ª´ file `links.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/links.csv\")\n",
    "links = data.links.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_url(url):\n",
    "    \"\"\"Check if the URL is valid.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.scheme and parsed.netloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thu th·∫≠p c√°c thu·ªôc t√≠nh c·ªßa t·ª´ng s·∫£n ph·∫©m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = []\n",
    "counter = 0  \n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ch·∫°y √¥ d∆∞·ªõi ƒë√¢y nhi·ªÅu l·∫ßn cho ƒë·∫øn khi n√†o thu th·∫≠p ƒë∆∞·ª£c h·∫øt to√†n b·ªô s·∫£n ph·∫©m th√¨ th√¥i**\n",
    "\n",
    "V√¨ c√≥ tr∆∞·ªùng h·ª£p ch·∫°y m√† m·∫°ng b·ªã ng·∫Øt gi·ªØa ch·ª´ng, ho·∫∑c driver b·ªã crash, ho·∫∑c t·ª± ƒë·ªông ng·∫Øt k·∫øt n·ªëi notebook trong VSCode hay Google Colab,...\n",
    "\n",
    "·ªû ƒë√¢y, √¥ b√™n d∆∞·ªõi ƒë√£ ƒë∆∞·ª£c ch·∫°y 2 l·∫ßn th√¨ ho√†n th√†nh thu th·∫≠p (`T·ª´ cell [6] ƒë·∫øn cell [8]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ thu th·∫≠p: 1444/1444 s·∫£n ph·∫©m\r"
     ]
    }
   ],
   "source": [
    "for i in range(counter, len(links)):\n",
    "    links[i] = links[i].strip()  # X√≥a kho·∫£ng tr·∫Øng ƒë·∫ßu v√† cu·ªëi\n",
    "    if not is_valid_url(links[i]):\n",
    "        print(f\"Invalid URL: {links[i]}\")\n",
    "        continue  # Skip invalid URLs\n",
    "        \n",
    "    driver.get(links[i])\n",
    "    # time.sleep(3)  # Ch·ªù trang t·∫£i\n",
    "\n",
    "    # try:\n",
    "    #     # Wait until the element with the text \"T∆Ø V·∫§N M√ÅY C≈®\" appears\n",
    "    #     element = WebDriverWait(driver, 10).until(\n",
    "    #         EC.presence_of_element_located((By.XPATH, \"//*[contains(text(), 'T∆Ø V·∫§N M√ÅY C≈®')]\"))\n",
    "    #     )\n",
    "    #     # print(\"Element appeared!\")\n",
    "    # except:    \n",
    "    #     print(\"Element did not appear within the given time\")   \n",
    "    \n",
    "    # try:\n",
    "    #     # button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, 'altumcode-close')))\n",
    "    #     button = driver.find_elements(By.XPATH, '//button[@class=\"altumcode-close\"]')\n",
    "    #     for b in button:\n",
    "    #         b.click()\n",
    "    # except:\n",
    "    #     button = None\n",
    "\n",
    "    # L·∫•y HTML trang hi·ªán t·∫°i\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Thu th·∫≠p t√™n s·∫£n ph·∫©m\n",
    "    try:\n",
    "        product_title = soup.find(\"h1\", class_=\"title\").text.strip()\n",
    "    except AttributeError:\n",
    "        product_title = \"Kh√¥ng c√≥ t√™n s·∫£n ph·∫©m\"\n",
    "\n",
    "    # Thu th·∫≠p h√£ng ƒëi·ªán tho·∫°i\n",
    "    second_li = driver.find_element(By.XPATH, '//ul[@itemscope]/li[2]/a/span')\n",
    "    brand = second_li.text.strip()\n",
    "\n",
    "    # L·∫•y th√¥ng tin v·ªÅ th·ªùi gian b·∫£o h√†nh\n",
    "    try:\n",
    "        warranty_text = soup.find('span', class_='warranty-content-default').get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        warranty_text = \"Kh√¥ng c√≥ th√¥ng tin b·∫£o h√†nh\"\n",
    "\n",
    "    # L·∫•y th√¥ng s·ªë k·ªπ thu·∫≠t\n",
    "    try:\n",
    "        specs_table = soup.find('div', class_='product-info-content').find('table')\n",
    "        specs = {}\n",
    "        if specs_table:\n",
    "            rows = specs_table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if len(cols) == 2:\n",
    "                    specs[cols[0].text.strip()] = cols[1].text.strip()\n",
    "    except AttributeError:\n",
    "        specs = {\"Kh√¥ng c√≥ th√¥ng s·ªë k·ªπ thu·∫≠t\": \"N/A\"}\n",
    "\n",
    "    # Thu th·∫≠p th√¥ng tin ƒë√°nh gi√°\n",
    "    try:\n",
    "        rating = soup.find('div', class_='comment-vote__star-number').get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        rating = \"Kh√¥ng c√≥ ƒë√°nh gi√°\"\n",
    "\n",
    "    # Thu th·∫≠p th√¥ng tin s·ªë l∆∞·ª£t ƒë√°nh gi√° v√† h·ªèi ƒë√°p\n",
    "    try:\n",
    "        total_reviews = soup.find('div', class_='comment-vote__star-total').get_text(strip=True)\n",
    "        total_reviews = total_reviews.replace(\"ƒë√°nh gi√° v√† h·ªèi ƒë√°p\", \"\").strip()\n",
    "    except AttributeError:\n",
    "        total_reviews = \"Kh√¥ng c√≥ th√¥ng tin ƒë√°nh gi√° v√† h·ªèi ƒë√°p\"\n",
    "\n",
    "    ##### M√†u s·∫Øc + Phi√™n b·∫£n b·ªô nh·ªõ + Gi√° t∆∞∆°ng ·ª©ng\n",
    "\n",
    "    color_storage_price = []\n",
    "    color_items = driver.find_elements(By.CLASS_NAME, \"color-item.attribute-item\")\n",
    "    storage_items = driver.find_elements(By.CLASS_NAME, \"storage-item.attribute-item\")\n",
    "\n",
    "    if len(color_items) == 0 and len(storage_items) == 0:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        try:\n",
    "            price_new = soup.find(\"p\", class_=\"price\").text.strip()\n",
    "        except AttributeError:\n",
    "            price_new = \"Kh√¥ng c√≥ gi√° m·ªõi\"\n",
    "        try:\n",
    "            price_old = soup.find(\"p\", class_=\"price-old\").text.strip()\n",
    "        except AttributeError:\n",
    "            price_old = \"Kh√¥ng c√≥ gi√° c≈©\"\n",
    "        color_storage_price.append([\"\", \"\", price_new, price_old])\n",
    "    elif len(color_items) == 0:\n",
    "        for storage in storage_items:\n",
    "            # storage.click()\n",
    "            while True:\n",
    "                try:\n",
    "                    storage.click()\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            storage_name = storage.text.strip()\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            try:\n",
    "                price_new = soup.find(\"p\", class_=\"price\").text.strip()\n",
    "            except AttributeError:\n",
    "                price_new = \"Kh√¥ng c√≥ gi√° m·ªõi\"\n",
    "            try:\n",
    "                price_old = soup.find(\"p\", class_=\"price-old\").text.strip()\n",
    "            except AttributeError:\n",
    "                price_old = \"Kh√¥ng c√≥ gi√° c≈©\"\n",
    "            color_storage_price.append([\"\", storage_name, price_new, price_old])\n",
    "    elif len(storage_items) == 0:\n",
    "        for color in color_items:\n",
    "            # color.click()\n",
    "            while True:\n",
    "                try:\n",
    "                    color.click()\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            color_name = color.get_attribute(\"data-title\")\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            try:\n",
    "                price_new = soup.find(\"p\", class_=\"price\").text.strip()\n",
    "            except AttributeError:\n",
    "                price_new = \"Kh√¥ng c√≥ gi√° m·ªõi\"\n",
    "            try:\n",
    "                price_old = soup.find(\"p\", class_=\"price-old\").text.strip()\n",
    "            except AttributeError:\n",
    "                price_old = \"Kh√¥ng c√≥ gi√° c≈©\"\n",
    "            color_storage_price.append([color_name, \"\", price_new, price_old])\n",
    "    else:\n",
    "        for color in color_items:\n",
    "            for storage in storage_items:\n",
    "                # color.click()\n",
    "                # storage.click()\n",
    "                while True:\n",
    "                    try:\n",
    "                        color.click()\n",
    "                        storage.click()\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                color_name = color.get_attribute(\"data-title\")\n",
    "                storage_name = storage.text.strip()\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                try:\n",
    "                    price_new = soup.find(\"p\", class_=\"price\").text.strip()\n",
    "                except AttributeError:\n",
    "                    price_new = \"Kh√¥ng c√≥ gi√° m·ªõi\"\n",
    "                try:\n",
    "                    price_old = soup.find(\"p\", class_=\"price-old\").text.strip()\n",
    "                except AttributeError:\n",
    "                    price_old = \"Kh√¥ng c√≥ gi√° c≈©\"    \n",
    "                color_storage_price.append([color_name, storage_name, price_new, price_old])\n",
    "\n",
    "    # # Thu th·∫≠p m√†u s·∫Øc\n",
    "    # try:\n",
    "    #     color_items = soup.find_all(\"div\", class_=\"color-item\")\n",
    "    #     colors = [color['data-title'] for color in color_items]\n",
    "    # except AttributeError:\n",
    "    #     colors = [\"Kh√¥ng c√≥ m√†u s·∫Øc\"]\n",
    "\n",
    "    # # L·∫•y th√¥ng tin v·ªÅ c√°c phi√™n b·∫£n b·ªô nh·ªõ\n",
    "    # try:\n",
    "    #     storage_items = soup.find_all('div', class_='storage-item attribute-item')\n",
    "    #     storage_options = [item.text.strip() for item in storage_items]\n",
    "    # except AttributeError:\n",
    "    #     storage_options = [\"Kh√¥ng c√≥ phi√™n b·∫£n b·ªô nh·ªõ\"]\n",
    "\n",
    "    # # Thu th·∫≠p gi√° s·∫£n ph·∫©m (gi√° m·ªõi v√† gi√° c≈©)\n",
    "    # try:\n",
    "    #     price_new = soup.find(\"p\", class_=\"price\").text.strip()\n",
    "    # except AttributeError:\n",
    "    #     price_new = \"Kh√¥ng c√≥ gi√° m·ªõi\"\n",
    "\n",
    "    # try:\n",
    "    #     price_old = soup.find(\"p\", class_=\"price-old\").text.strip()\n",
    "    # except AttributeError:\n",
    "    #     price_old = \"Kh√¥ng c√≥ gi√° c≈©\"\n",
    "\n",
    "    #####\n",
    "\n",
    "    product_data.append({\n",
    "        \"T√™n s·∫£n ph·∫©m\": product_title,\n",
    "        \"Lo·∫°i ƒëi·ªán tho·∫°i\": brand,\n",
    "        # \"Gi√° m·ªõi\": price_new,\n",
    "        # \"Gi√° c≈©\": price_old,\n",
    "        # \"M√†u s·∫Øc\": \", \".join(colors),\n",
    "        # \"C√°c phi√™n b·∫£n b·ªô nh·ªõ\": \", \".join(storage_options),\n",
    "        \"M√†u s·∫Øc - Phi√™n b·∫£n b·ªô nh·ªõ - Gi√° t∆∞∆°ng ·ª©ng\": color_storage_price,\n",
    "        \"Th·ªùi gian b·∫£o h√†nh\": warranty_text,\n",
    "        \"Th√¥ng s·ªë k·ªπ thu·∫≠t\": json.dumps(specs, ensure_ascii=False),\n",
    "        \"ƒê√°nh gi√°\": rating,\n",
    "        \"S·ªë l∆∞·ª£t ƒë√°nh gi√° v√† h·ªèi ƒë√°p\": total_reviews,\n",
    "        \"ƒê∆∞·ªùng d·∫´n\": links[i],\n",
    "    })\n",
    "    counter +=1\n",
    "    # if counter % 100 == 0:\n",
    "    #     print(f\"ƒê√£ thu th·∫≠p th√†nh c√¥ng {counter} s·∫£n ph·∫©m\")\n",
    "    print(f\"ƒê√£ thu th·∫≠p: {counter}/{len(links)} s·∫£n ph·∫©m\", end=\"\\r\")\n",
    "\n",
    "# In th√¥ng b√°o khi ho√†n th√†nh\n",
    "# print(\"Ho√†n th√†nh!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th·ªùi gian k·∫øt th√∫c thu th·∫≠p: 2024-12-18 09:17:23\n"
     ]
    }
   ],
   "source": [
    "# Get current time\n",
    "current_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "# Print the current time\n",
    "print(\"Th·ªùi gian k·∫øt th√∫c thu th·∫≠p:\", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L∆∞u d·ªØ li·ªáu thu th·∫≠p ƒë∆∞·ª£c v√†o file `raw_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u d·ªØ li·ªáu v√†o file CSV\n",
    "with open('../data/raw_data.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    fieldnames = product_data[0].keys()  # L·∫•y c√°c t√™n tr∆∞·ªùng t·ª´ ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for data in product_data:\n",
    "        writer.writerow(data)\n",
    "\n",
    "# ƒê√≥ng tr√¨nh duy·ªát\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset n√†y bao g·ªìm c√°c thu·ªôc t√≠nh:\n",
    "- `Index`: s·ªë th·ª© t·ª± c·ªßa ƒë∆∞·ªùng d·∫´n ƒë·∫øn t·ª´ng ƒëi·ªán tho·∫°i tr√™n trang web MobileCity.\n",
    "- `T√™n s·∫£n ph·∫©m`: t√™n c·ªßa t·ª´ng ƒëi·ªán tho·∫°i.\n",
    "- `Lo·∫°i ƒëi·ªán tho·∫°i`: ch·ª©a lo·∫°i ƒëi·ªán tho·∫°i ƒë∆∞·ª£c ph√¢n lo·∫°i theo trang web MobileCity.\n",
    "- `M√†u s·∫Øc - Phi√™n b·∫£n b·ªô nh·ªõ - Gi√° t∆∞∆°ng ·ª©ng`: l√† m·ªôt danh s√°ch c√°c m·∫´u ƒëi·ªán tho·∫°i c·ªßa c√πng m·ªôt t√™n ƒëi·ªán tho·∫°i, m·ªói ph·∫ßn t·ª≠ trong danh s√°ch c≈©ng l√† m·ªôt danh s√°ch bao g·ªìm m√†u s·∫Øc, phi√™n b·∫£n b·ªô nh·ªõ v√† gi√° t∆∞∆°ng ·ª©ng c·ªßa m·∫´u ƒëi·ªán tho·∫°i ƒë√≥.\n",
    "- `Th·ªùi gian b·∫£o h√†nh`: ch·ª©a th√¥ng tin b·∫£o h√†nh c·ªßa ƒëi·ªán tho·∫°i (ƒë∆°n v·ªã th√°ng/nƒÉm)\n",
    "- `Th√¥ng s·ªë k·ªπ thu·∫≠t`: l√† m·ªôt t·ª´ ƒëi·ªÉn v·ªõi c√°c gi√° tr·ªã t∆∞∆°ng ·ª©ng v·ªõi c√°c kh√≥a sau: M√†n h√¨nh, H·ªá ƒëi·ªÅu h√†nh, Camera sau, Camera tr∆∞·ªõc, CPU, RAM, B·ªô nh·ªõ trong, Th·∫ª SIM, Dung l∆∞·ª£ng pin, Thi·∫øt k·∫ø.\n",
    "- `ƒê√°nh gi√°`: l√† ƒë√°nh gi√° c·ªßa ƒëi·ªán tho·∫°i tr√™n trang web MobileCity (t·ª´ 0-5 sao) ·ª©ng v·ªõi m·ªói t√™n ƒëi·ªán tho·∫°i.\n",
    "- `S·ªë l∆∞·ª£t ƒë√°nh gi√° v√† h·ªèi ƒë√°p`: l√† s·ªë l∆∞·ª£ng ƒë√°nh gi√° v√† h·ªèi ƒë√°p tr√™n trang web MobileCity ·ª©ng v·ªõi m·ªói t√™n ƒëi·ªán tho·∫°i.\n",
    "- `ƒê∆∞·ªùng d·∫´n`: ch·ª©a ƒë∆∞·ªùng d·∫´n ƒë·∫øn t√™n ƒëi·ªán tho·∫°i t∆∞∆°ng ·ª©ng tr√™n trang web MobileCity.\n",
    "\n",
    "T·ªïng c·ªông c√≥ `1444` s·∫£n ph·∫©m, t∆∞∆°ng ·ª©ng `1444` t√™n ƒëi·ªán tho·∫°i kh√°c nhau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
